{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IMDB_Embedding.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"towaIVGlFFWi","colab_type":"text"},"source":["**Set Up**"]},{"cell_type":"code","metadata":{"id":"WzWGcS9QEvIi","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","\n","import collections\n","import io\n","import math\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from IPython import display\n","from sklearn import metrics\n","\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","train_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n","train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n","test_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n","test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGx8hLx5FK6d","colab_type":"text"},"source":["**Pre-processing tools**"]},{"cell_type":"code","metadata":{"id":"T2CRFGFIFPQc","colab_type":"code","colab":{}},"source":["def _parse_function(record):\n","  \"\"\"Extracts features and labels.\n","  \n","  Args:\n","    record: File path to a TFRecord file    \n","  Returns:\n","    A `tuple` `(labels, features)`:\n","      features: A dict of tensors representing the features\n","      labels: A tensor with the corresponding labels.\n","  \"\"\"\n","  features = {\n","    \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n","    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n","  }\n","  \n","  parsed_features = tf.parse_single_example(record, features)\n","  \n","  terms = parsed_features['terms'].values\n","  labels = parsed_features['labels']\n","\n","  return  {'terms':terms}, labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oIXdirFpFqRy","colab_type":"text"},"source":["Build a formal input function that we can pass to the train() method of a TensorFlow Estimator object."]},{"cell_type":"code","metadata":{"id":"f1_StLeiFl7o","colab_type":"code","colab":{}},"source":["# Create an input_fn that parses the tf.Examples from the given files,\n","# and split them into features and targets.\n","def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n","  \n","  # Same code as above; create a dataset and map features and labels.\n","  ds = tf.data.TFRecordDataset(input_filenames)\n","  ds = ds.map(_parse_function)\n","\n","  if shuffle:\n","    ds = ds.shuffle(10000)\n","\n","  # Our feature data is variable-length, so we pad and batch\n","  # each field of the dataset structure to whatever size is necessary.\n","  ds = ds.padded_batch(25, ds.output_shapes)\n","  \n","  ds = ds.repeat(num_epochs)\n","\n","  \n","  # Return the next batch of data.\n","  features, labels = ds.make_one_shot_iterator().get_next()\n","  return features, labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFd6OUnBF8rZ","colab_type":"code","outputId":"6b7097a0-5bcf-4247-d7b3-e3df156bea94","executionInfo":{"status":"error","timestamp":1572248170582,"user_tz":300,"elapsed":2852,"user":{"displayName":"Truong Luu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_4w4EEnooOdou48JU16JvIXo3lywfwb8IWrsleg=s64","userId":"01893867099211429989"}},"colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n","feature_columns = [ terms_embedding_column ]\n","\n","my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n","my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n","\n","classifier = tf.estimator.DNNClassifier(\n","  feature_columns=feature_columns,\n","  hidden_units=[20,20],\n","  optimizer=my_optimizer\n",")\n","\n","classifier.train(\n","  input_fn=lambda: _input_fn([train_path]),\n","  steps=1000)\n","\n","evaluation_metrics = classifier.evaluate(\n","  input_fn=lambda: _input_fn([train_path]),\n","  steps=1000)\n","print(\"Training set metrics:\")\n","for m in evaluation_metrics:\n","  print(m, evaluation_metrics[m])\n","print(\"---\")\n","\n","evaluation_metrics = classifier.evaluate(\n","  input_fn=lambda: _input_fn([test_path]),\n","  steps=1000)\n","\n","print(\"Test set metrics:\")\n","for m in evaluation_metrics:\n","  print(m, evaluation_metrics[m])\n","print(\"---\")"],"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-6a140d03365d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mterms_embedding_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms_feature_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mterms_embedding_column\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmy_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdagradOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmy_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_gradients_by_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'terms_feature_column' is not defined"]}]},{"cell_type":"code","metadata":{"id":"m7u_tln2Gh5I","colab_type":"code","outputId":"824233ac-1ce6-416e-d592-c0ce69af0c9d","executionInfo":{"status":"error","timestamp":1571674531834,"user_tz":300,"elapsed":371,"user":{"displayName":"Truong Luu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_4w4EEnooOdou48JU16JvIXo3lywfwb8IWrsleg=s64","userId":"01893867099211429989"}},"colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["try:\n","  classifier.train(\n","    input_fn=lambda: _input_fn([train_path]),\n","    steps=1000)\n","\n","  evaluation_metrics = classifier.evaluate(\n","    input_fn=lambda: _input_fn([train_path]),\n","    steps=1)\n","  print(\"Training set metrics:\")\n","  for m in evaluation_metrics:\n","    print(m, evaluation_metrics[m])\n","  print(\"---\")\n","\n","  evaluation_metrics = classifier.evaluate(\n","    input_fn=lambda: _input_fn([test_path]),\n","    steps=1)\n","\n","  print(\"Test set metrics:\")\n","  for m in evaluation_metrics:\n","    print(m, evaluation_metrics[m])\n","  print(\"---\")\n","except ValueError as err:\n","  print(err)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0ada57870d35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   classifier.train(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     steps=1000)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"]}]}]}